# GUIDE â€“ MLOps **Redâ€¯Wine Quality**

DockerÂ +Â MLflowÂ +Â PostgreSQLÂ +Â pgAdminÂ +Â PortainerÂ +Â **FastAPI**Â +Â **Streamlit** +Â **CI/CD GitHub Actions** +Â **Docker Hub**

> **Extension par rapport Ã  la version prÃ©cÃ©dente**â€¯:
> â€“ Ajout dâ€™une API REST (FastAPIâ€¯: portâ€¯8000)
> â€“ Ajout dâ€™un tableau de bord interactif (Streamlitâ€¯: portâ€¯8501)
> â€“ PossibilitÃ© de lancer â€“ depuis le navigateur â€“ des entraÃ®nements MLflow avec hyperâ€‘paramÃ¨tres choisis Ã  la volÃ©e, dâ€™observer les runs en temps rÃ©el et de servir les prÃ©dictions.


<br/>

# 0. TABLE DES PORTS

| Service    | Port conteneur | Port hÃ´te | Description courte         |
| ---------- | -------------- | --------- | -------------------------- |
| MLflow UI  | 5000           | 5000      | Suivi des expÃ©riences      |
| FastAPI    | 8000           | 8000      | API REST (train + predict) |
| Streamlit  | 8501           | 8501      | Dashboard interactif       |
| PostgreSQL | 5432           | 5432      | Base de donnÃ©es MLflow     |
| pgAdmin    | 80             | 8080      | GUI PostgreSQL             |
| Portainer  | 9000           | 9000      | Supervision conteneurs     |

Assurezâ€‘vous dâ€™ouvrir **5000,â€¯8000,â€¯8501,â€¯8080,â€¯9000** (TCP entrants) dans votre pareâ€‘feuâ€¯/â€¯NSG.



<br/>

# 1. FICHIERS Ã€ CRÃ‰ER / MODIFIER

```
mlops-redwine/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ train_model.py
â”œâ”€â”€ api_app.py           <-- FastAPI
â”œâ”€â”€ streamlit_app.py     <-- Streamlit
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ data/
â”‚   â””â”€â”€ red-wine-quality.csv
â””â”€â”€ mlruns/
```



### 1.1 `requirements.txt` (complÃ©tÃ©)

```
pandas
numpy
scikit-learn
mlflow
psycopg2-binary
fastapi
uvicorn[standard]
streamlit
```



### 1.2 `Dockerfile` (un seul conteneur Â«Â mlflowÂ Â» sachant tout faire)

```dockerfile
FROM python:3.11-slim

# Installation des dÃ©pendances systÃ¨me (pour scikit-learn, pandas, etc.)
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \
    git \
    curl \
    libpq-dev \
    && apt-get clean \
    && rm -rf /var/lib/apt/lists/*

# DÃ©finir le dossier de travail
WORKDIR /app

# Copier les fichiers du projet
COPY . .

# Mise Ã  jour de pip et installation des packages Python requis
RUN pip install --upgrade pip && pip install -r requirements.txt

# DÃ©finir le point dâ€™entrÃ©e par dÃ©faut pour le conteneur
CMD ["bash"]

```



### 1.3 `train_model.py`

```python

import argparse, os, sys
import pandas as pd, numpy as np
import mlflow, mlflow.sklearn
from mlflow.models.signature import infer_signature
from sklearn.model_selection import train_test_split
from sklearn.linear_model import ElasticNet, Ridge, Lasso
from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score

# ---------- 1. CLI ----------
cli = argparse.ArgumentParser()
cli.add_argument("--model", required=True,
                 choices=["elasticnet", "ridge", "lasso", "randomforest", "gbrt"])
cli.add_argument("--alpha", type=float, default=0.5)         # utilisÃ© par linÃ©aires
cli.add_argument("--l1_ratio", type=float, default=0.5)      # utilisÃ© uniquement par ElasticNet
args = cli.parse_args()

# ---------- 2. MLflow ----------
tracking_uri = os.getenv("MLFLOW_TRACKING_URI", "http://mlflow:5000")
mlflow.set_tracking_uri(tracking_uri)
experiment_name = f"mlops_redwine_{args.model}"
mlflow.set_experiment(experiment_name)

# ---------- 3. DonnÃ©es ----------
csv_path = "data/red-wine-quality.csv"
if not os.path.exists(csv_path):
    sys.exit(f"Fichier introuvable : {csv_path}")
df = pd.read_csv(csv_path, sep=';')  # sÃ©parateur correct

X = df.drop("quality", axis=1)
y = df["quality"]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)

def log_metrics(y_true, y_pred):
    return {
        "rmse": np.sqrt(mean_squared_error(y_true, y_pred)),
        "mae":  mean_absolute_error(y_true, y_pred),
        "r2":   r2_score(y_true, y_pred)
    }

# ---------- 4. EntraÃ®nement ----------
with mlflow.start_run() as run:
    # SÃ©lection du modÃ¨le
    if args.model == "elasticnet":
        model = ElasticNet(alpha=args.alpha, l1_ratio=args.l1_ratio, random_state=42)
        mlflow.log_param("l1_ratio", args.l1_ratio)
        mlflow.log_param("alpha", args.alpha)

    elif args.model == "ridge":
        model = Ridge(alpha=args.alpha, random_state=42)
        mlflow.log_param("alpha", args.alpha)

    elif args.model == "lasso":
        model = Lasso(alpha=args.alpha, random_state=42)
        mlflow.log_param("alpha", args.alpha)

    elif args.model == "randomforest":
        model = RandomForestRegressor(n_estimators=100, random_state=42)

    elif args.model == "gbrt":
        model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)

    else:
        sys.exit("ModÃ¨le non pris en charge.")

    # Apprentissage
    model.fit(X_train, y_train)
    preds = model.predict(X_test)

    # Log des mÃ©triques
    for k, v in log_metrics(y_test, preds).items():
        mlflow.log_metric(k, float(v))

    # CrÃ©ation de la signature
    input_example = X_train.iloc[:1]
    signature = infer_signature(X_train, model.predict(X_train))

    # Log du modÃ¨le avec signature et exemple
    mlflow.sklearn.log_model(model, "model", signature=signature, input_example=input_example)

    # Enregistrement dans le registry
    model_name = "RedWineModel"
    model_uri = f"runs:/{run.info.run_id}/model"
    mlflow.register_model(model_uri, model_name)

    # Passage Ã  Production
    client = mlflow.tracking.MlflowClient()
    latest_version = client.get_latest_versions(model_name, stages=["None"])[0].version
    client.transition_model_version_stage(
        name=model_name,
        version=latest_version,
        stage="Production",
        archive_existing_versions=True
    )

    print(f"ModÃ¨le '{args.model}' enregistrÃ© et promu en Production.")

---

### 1.4 `api_app.py` â€” **FastAPI**

```python
from fastapi import FastAPI
from pydantic import BaseModel
from typing import Optional
import subprocess, uuid, os
import mlflow.pyfunc
import pandas as pd

app = FastAPI(title="Redâ€‘Wine MLOps API")

# ----------- TRAIN REQUEST -----------
class TrainRequest(BaseModel):
    model: str  # elasticnet | ridge | lasso | randomforest | gbrt
    alpha: Optional[float] = None
    l1_ratio: Optional[float] = None

@app.post("/train")
def train(req: TrainRequest):
    run_id = str(uuid.uuid4())[:8]
    cmd = [
        "python", "train_model.py",
        "--model", req.model
    ]
    if req.alpha is not None:
        cmd += ["--alpha", str(req.alpha)]
    if req.model == "elasticnet" and req.l1_ratio is not None:
        cmd += ["--l1_ratio", str(req.l1_ratio)]
    
    env = os.environ.copy()
    env["MLFLOW_TRACKING_URI"] = env.get("MLFLOW_TRACKING_URI", "http://mlflow:5000")
    subprocess.Popen(cmd, env=env)
    
    return {"status": "started", "run_id": run_id, "cmd": " ".join(cmd)}

# ----------- PREDICT REQUEST -----------
class PredictRequest(BaseModel):
    fixed_acidity: float
    volatile_acidity: float
    citric_acid: float
    residual_sugar: float
    chlorides: float
    free_sulfur_dioxide: float
    total_sulfur_dioxide: float
    density: float
    pH: float
    sulphates: float
    alcohol: float

@app.post("/predict")
def predict(inp: PredictRequest):
    try:
        # Dictionnaire reÃ§u depuis le frontend
        input_dict = inp.dict()

        # Mapping des noms reÃ§us (underscores) vers les noms attendus par le modÃ¨le (espaces)
        rename_map = {
            "fixed_acidity": "fixed acidity",
            "volatile_acidity": "volatile acidity",
            "citric_acid": "citric acid",
            "residual_sugar": "residual sugar",
            "chlorides": "chlorides",
            "free_sulfur_dioxide": "free sulfur dioxide",
            "total_sulfur_dioxide": "total sulfur dioxide",
            "density": "density",
            "pH": "pH",
            "sulphates": "sulphates",
            "alcohol": "alcohol"
        }

        # Conversion du dictionnaire vers DataFrame avec les bons noms de colonnes
        renamed_input = {rename_map[k]: v for k, v in input_dict.items()}
        X = pd.DataFrame([renamed_input])

        # Chargement du modÃ¨le promu en production
        model_uri = "models:/RedWineModel/Production"
        model = mlflow.pyfunc.load_model(model_uri)

        # PrÃ©diction
        pred = model.predict(X)[0]
        return {"quality_estimate": round(float(pred), 2)}

    except Exception as e:
        return {"error": str(e)}

```



### 1.5 `streamlit_app.py` â€” **Dashboard**

```python
import streamlit as st
import requests
import pandas as pd
import os
from urllib.parse import urljoin

st.set_page_config(page_title="Red Wine Quality Trainer", layout="centered")
st.title("ğŸ· Red Wine Quality MLOps App")

# ---------- Configuration de l'URL de l'API ----------
API_BASE_URL = os.getenv("API_URL", "http://backend:8000")  # Utilise la variable d'environnement ou la valeur par dÃ©faut
TRAIN_ENDPOINT = urljoin(API_BASE_URL, "/train")
PREDICT_ENDPOINT = urljoin(API_BASE_URL, "/predict")

# ---------- 1. ParamÃ¨tres d'entraÃ®nement ----------
with st.form("train_form"):
    st.header("ğŸ”§ EntraÃ®nement du modÃ¨le")
    model_type = st.selectbox("Choisissez un modÃ¨le", ["elasticnet", "ridge", "lasso", "randomforest", "gbrt"])
    alpha = st.number_input("Alpha", value=0.5, step=0.01)
    l1_ratio = st.number_input("L1 Ratio (ElasticNet uniquement)", value=0.5, step=0.01)
    train_btn = st.form_submit_button("Lancer l'entraÃ®nement")

    if train_btn:
        payload = {"model": model_type}
        if model_type in ["elasticnet", "ridge", "lasso"]:
            payload["alpha"] = alpha
        if model_type == "elasticnet":
            payload["l1_ratio"] = l1_ratio

        with st.spinner("EntraÃ®nement en cours..."):
            try:
                r = requests.post(TRAIN_ENDPOINT, json=payload, timeout=30)
                r.raise_for_status()
                resp_json = r.json()
                st.success(f"âœ… EntraÃ®nement terminÃ©: Run ID {resp_json.get('run_id', '')}")

                if "metrics" in resp_json:
                    st.subheader("ğŸ“Š RÃ©sultats d'entraÃ®nement")
                    metrics = resp_json["metrics"]
                    cols = st.columns(3)
                    cols[0].metric("RMSE", round(metrics.get("rmse", 0), 4))
                    cols[1].metric("MAE", round(metrics.get("mae", 0), 4))
                    cols[2].metric("RÂ²", round(metrics.get("r2", 0), 4))

            except requests.exceptions.RequestException as e:
                st.error(f"âŒ Erreur de connexion Ã  l'API: {str(e)}")
            except ValueError as e:
                st.error(f"âŒ RÃ©ponse JSON invalide: {str(e)}")

# ---------- 2. PrÃ©diction ----------
st.header("ğŸ”® PrÃ©diction de la qualitÃ©")

input_fields = {
    "fixed_acidity": ("Fixed acidity", 5.0),
    "volatile_acidity": ("Volatile acidity", 0.5),
    "citric_acid": ("Citric acid", 0.5),
    "residual_sugar": ("Residual sugar", 2.0),
    "chlorides": ("Chlorides", 0.1),
    "free_sulfur_dioxide": ("Free sulfur dioxide", 15.0),
    "total_sulfur_dioxide": ("Total sulfur dioxide", 30.0),
    "density": ("Density", 0.995),
    "pH": ("pH", 3.5),
    "sulphates": ("Sulphates", 0.5),
    "alcohol": ("Alcohol", 10.0)
}

inputs = {}
for field, (label, default) in input_fields.items():
    inputs[field] = st.number_input(label, value=default, step=0.01)

if st.button("PrÃ©dire la qualitÃ©"):
    with st.spinner("Calcul de la prÃ©diction..."):
        try:
            response = requests.post(PREDICT_ENDPOINT, json=inputs, timeout=10)
            response.raise_for_status()

            result = response.json()
            if "quality_estimate" in result:
                st.success(f"ğŸ¯ QualitÃ© estimÃ©e: {result['quality_estimate']:.1f}/10")
            else:
                st.error(f"âš ï¸ Format de rÃ©ponse inattendu: {result}")

        except requests.exceptions.RequestException as e:
            st.error(f"âŒ Erreur de connexion: {str(e)}")
        except ValueError as e:
            st.error(f"âŒ RÃ©ponse JSON invalide: {str(e)}")

```



### 1.6 `docker-compose.yml` (mis Ã  jour)

```yaml
services:
  # ---------- PostgreSQL ----------
  postgres:
    image: postgres:14
    restart: unless-stopped
    environment:
      POSTGRES_USER: mlflow
      POSTGRES_PASSWORD: mlflow
      POSTGRES_DB: mlflow_db
    ports: ["5432:5432"]
    volumes: [postgres_data:/var/lib/postgresql/data]
    networks:  # AjoutÃ©
      - mlflow_network

  # ---------- Backend MLflow + code commun ----------
  mlflow:
    build: .
    restart: unless-stopped
    depends_on: [postgres]
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
    command: >
      mlflow server
      --backend-store-uri postgresql://mlflow:mlflow@postgres:5432/mlflow_db
      --default-artifact-root /app/mlruns
      --host 0.0.0.0
    ports: ["5000:5000"]
    volumes:
      - ./mlruns:/app/mlruns
      - ./data:/app/data
    networks:  # AjoutÃ©
      - mlflow_network

  # ---------- FastAPI ----------
  api:
    build: .
    restart: unless-stopped
    depends_on: [mlflow]
    environment:
      MLFLOW_TRACKING_URI: http://mlflow:5000
    command: uvicorn api_app:app --host 0.0.0.0 --port 8000 --reload
    ports: ["8000:8000"]
    volumes:
      - ./data:/app/data
      - ./mlruns:/app/mlruns
    networks:  # AjoutÃ©
      - mlflow_network

  # ---------- Streamlit ----------
  streamlit:
    build: .
    restart: unless-stopped
    depends_on: [api]
    environment:
      STREAMLIT_SERVER_PORT: 8501
      MLFLOW_TRACKING_URI: http://mlflow:5000
      API_URL: http://api:8000  # Utilise le nom du service "api"
    command: streamlit run streamlit_app.py --server.port 8501 --server.address 0.0.0.0
    ports: ["8501:8501"]
    volumes:
      - ./data:/app/data
      - ./mlruns:/app/mlruns
    networks:  # AjoutÃ©
      - mlflow_network

  # ---------- pgAdmin ----------
  pgadmin:
    image: dpage/pgadmin4
    restart: unless-stopped
    environment:
      PGADMIN_DEFAULT_EMAIL: admin@admin.com
      PGADMIN_DEFAULT_PASSWORD: admin
    ports: ["8080:80"]
    volumes: [pgadmin_data:/var/lib/pgadmin]
    networks:  # AjoutÃ© (optionnel)
      - mlflow_network

  # ---------- Portainer ----------
  portainer:
    image: portainer/portainer-ce
    restart: unless-stopped
    command: -H unix:///var/run/docker.sock
    ports: ["9000:9000"]
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - portainer_data:/data
    networks:  # AjoutÃ© (optionnel)
      - mlflow_network

volumes:
  postgres_data:
  pgadmin_data:
  portainer_data:

networks:  # Nouveau rÃ©seau ajoutÃ©
  mlflow_network:
    driver: bridge
```

<br/>

```
## MISE EN PLACE Dâ€™UNE PIPELINE CI/CD

### â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â• ASCIIÂ : Vue dâ€™ensemble â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—

```
 DÃ©veloppeur â”€â”€pushâ”€â”€â–¶ GitHub Repo â”€â”€GitHubÂ Actionsâ”€â”€â–¶ DockerÂ Hub â”€â”€pullâ”€â”€â–¶ Oracle VM
    |                                 (build &                                    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ SSH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ push) â—€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ webhooks â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

### 1. PrÃ©requis comptes

1.1 CrÃ©ez (ou utilisez) un compte **GitHub**.
1.2 CrÃ©ez (ou utilisez) un compte **Dockerâ€¯Hub**. Retenezâ€¯:
Â Â Â Â â€“ *NAMESPACE*â€¯: `alnyeck`
Â Â Â Â â€“ *REPOSITORY*â€¯: `projetsmlops-3`

### 2. Initialiser le dÃ©pÃ´t Git local

```bash
depuis mon repertoire 'projetsmlops-3' sur mon disque local Windows
git init
git add .
git commit -m "Initial commit â€“ stack MLOps"
git branch -M main
git remote add origin https://github.com/alnyeck/projetsmlops-3.git
git push -u origin main
```

*(remplacez `<votre_user>` par votre pseudo GitHub)*

### 3. CrÃ©er les **secrets** GitHub nÃ©cessaires

Dans **GitHub â†’ Settings â†’ Secrets â†’ Actions**â€¯:

| Nom du secret        | Valeur                                               |
| -------------------- | ---------------------------------------------------- |
| `DOCKERHUB_USERNAME` | votre identifiant Dockerâ€¯Hub: alnyeck                |
| `DOCKERHUB_PASSWORD` | un **Access Token** Dockerâ€¯Hub (pas le mot de passe) |
| `EMAIL_USERNAME`     | votre addresse email                                 |
| `EMAIL_PASSWORD`     | le mot de passe email                                |
| `SSH_HOST`           | IP publique de la VM: 192.168.56.101                 |


> Pour crÃ©er lâ€™AccessÂ Tokenâ€¯: Dockerâ€¯Hub â–º **AccountÂ Settings** â–º **Security** â–º **NewÂ AccessÂ Token** (scopesÂ : `Write`).

### 4. Ajouter le workflow GitHubÂ Actions

CrÃ©ez `.github/workflows/ci-cd.yml`â€¯:

```yaml
name: CIâ€‘CD Docker local

on:
  push:
    branches: [ main, test ]

jobs:
  build-and-push:
    runs-on: self-hosted
    steps:
      - uses: actions/checkout@v4

      - name: Connexion Ã  Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_PASSWORD }}

      - name: DÃ©finir le tag dâ€™image
        id: vars
        run: echo "TAG=${GITHUB_SHA::8}" >> $GITHUB_OUTPUT

      - name: Build & Push de lâ€™image Docker
        uses: docker/build-push-action@v5
        with:
          context: .
          push: true
          tags: ${{ secrets.DOCKERHUB_USERNAME }}/projetsmlops-3:${{ steps.vars.outputs.TAG }}

  deploy:
    needs: build-and-push
    runs-on: self-hosted
    steps:
      - name: DÃ©ploiement local avec docker-compose
        run: |
          cd /home/eleve/projetsmlops-3
          docker compose pull
          docker compose up -d

  notify:
    needs: deploy
    runs-on: ubuntu-latest
    steps:
      - name: Send email notification
        uses: dawidd6/action-send-mail@v3
        with:
          server_address: smtp.mail.yahoo.com
          server_port: 465
          secure: true
          username: ${{ secrets.EMAIL_USERNAME }}
          password: ${{ secrets.EMAIL_PASSWORD }}
          subject: âœ… CI/CD terminÃ© avec succÃ¨s
          to: a_nyeck@yahoo.com
          from: ${{ secrets.EMAIL_USERNAME }}
          body: |
            Le workflow CI/CD dans le dÃ©pÃ´t projetsmlops-3 s'est exÃ©cutÃ© avec succÃ¨s !
```

# 2. BUILD & LANCEMENT

```bash
sudo -s
git clone https://github.com/hrhouma/install-docker.git
cd install-docker
chmod +x install-docker.sh
./install-docker.sh           # installe Docker + compose plugin v2
apt install docker-compose
cd /home/eleve/
git clone https://github.com/alnyeck/projetsmlops-3.git
cd projetsmlops-3/
docker-compose pull
docker-compose build --no-cache mlflow
docker-compose up -d
docker ps --format "table {{.Names}}\t{{.Ports}}"
```

Vous devez voir **6Â services**â€¯: `postgres`, `mlflow`, `api`, `streamlit`, `pgadmin`, `portainer`.


<br/>

# 3. UTILISATION

| Ã‰tape | Action                                                                                                                                                                                                                                              |
| ----- | --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| 1     | Visitez **Streamlit**â€¯: `http://localhost:8501`.<br>Choisissez un modÃ¨le, rÃ©glez `alpha` et (pour ElasticNet) `l1_ratio`, cliquez **Lancer l'entraÃ®nement**.<br>Le run dÃ©marre et apparaÃ®t instantanÃ©ment dans **MLflow UI** (`http://localhost:5000`). |
| 2     | Testez lâ€™APIÂ RESTÂ :                                                                                                                                                                                                                                 |

*Depuis votre machine locale*â€¯:

```bash
curl -X POST http://<IP_VM>:8000/train \
  -H "Content-Type: application/json" \
  -d '{"model":"ridge","alpha":0.4}'
```

*PrÃ©diction rapide*â€¯:

```bash
curl -X POST http://<IP_VM>:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"alcohol":11.0,"volatile_acidity":0.6,"sulphates":0.75}'
```

Vous obtenez un JSON avec lâ€™estimation de qualitÃ©.

<br/>

---

## PHASE 3 â€” LANCEMENT DU PROJET

Dans le terminal :

```bash
docker-compose up --build
```

Attendez que les 3 services soient bien dÃ©marrÃ©s : `postgres`, `mlflow`, `pgadmin`.

---

## ACCÃˆS AUX AUTRES INTERFACES

### Interface MLflow :

Ouvrir dans un navigateur :

```
http://localhost:5000
```

---

### Interface pgAdmin :

Ouvrir dans un navigateur :

```
http://localhost:8080
```

**Identifiants :**

* Email : `admin@admin.com`
* Mot de passe : `admin`

**Ajout manuel de la base PostgreSQL dans pgAdmin :**

1. Cliquez sur "Add New Server"
2. Onglet "General" : Nom du serveur : `mlflow-db`
3. Onglet "Connection" :

   * Host name/address : `postgres`
   * Maintenance database : `mlflow_db`
   * Username : `mlflow`
   * Password : `mlflow`
4. Cliquez sur "Save"

---
# 4. POINTS Dâ€™AMÃ‰LIORATION

| IdÃ©e                         | Piste de miseâ€¯enâ€¯Å“uvre                                                                            |
| ---------------------------- | ------------------------------------------------------------------------------------------------- |
| Signature MLflow             | Utiliser `mlflow.models.signature.infer_signature` pour logger `input_example` et la `signature`. |
| Prediction via modÃ¨le MLflow | Charger le dernier modÃ¨le avec `mlflow.pyfunc.load_model` dans `api_app.py`.                      |
| Authentification API         | Ajouter `fastapi.security` + JWT ou clÃ© API simple.                                               |
| Monitoring                   | Activer Prometheus + Grafana via Portainer pour CPU/RAM.                                          |
| Tests unitaires              | Ajouter `pytest` + GitHubÂ Actions CI/CD (build + docker push).                                    |

<br/>

# Â 5. Notre stack MLOps est prÃªteâ€¯!

- PageÂ Streamlit conviviale, API REST pour scripts externes, suivi MLflow complet, baseÂ PostgreSQL, pgAdmin, Portainer â€” le tout en **unâ€¯seul `docker-compose up -d`**.
